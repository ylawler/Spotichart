# Project Evaluation

#### Objectives

As can be read in our [Development Plan](https://gitlab.ewi.tudelft.nl/ewi3615tu/2019-2020/data/ewi3615tu-ds10/ewi3615tu-ds10/blob/master/Documentation%20set/Development%20plan/Development%20Plan.md) and [Design Plan](https://gitlab.ewi.tudelft.nl/ewi3615tu/2019-2020/data/ewi3615tu-ds10/ewi3615tu-ds10/blob/master/Documentation%20set/Design%20plan/Design%20plan.md), our project's goal was to show which songs in the Spotify Chart are similar. To achieve this, we decided to cluster our songs using the K-Means algorithm and visualize the clusters on a Minimum Spanning Tree, which shows the songs that have a short distance between them and thus, are similar. We used the audio features made available by Spotify to determine the difference, or distance, between songs. The audio features are both factual features, such as tempo, and more subjective features like danceability and energy. In this project, we wanted to find out whether it is possible to create accurate lists of similar songs based on these features. 

#### Risk factors

We stated in the Development Plan three factors that can cause a risk for our project. The first and most important one is the tool that obtains the song characteristics. 
If we couldn't get this tool to work, we basically didn't have any data to process. We eventually found out that is was very simple to accomplish. The second risk factor was the machine learning. Because of the lack of experience with K-means we didn't know how much time it would take to get familiar with it. But with some examples and we managed to understand the algorithm well and how to implement it in our program. The last risk factor which will be discussed in the *Implementation* is the visualization on the minimum spanning tree. Our goals was to make a user friendly and easy to read graph that shows which songs are most connected to each other. Unfortunately, we couldn't visualize it as how we wanten to, so we started looking at PCA

#### Important Design Decisions

During our project we had to make some important decisions. The first one was to choose which algorithm to use to create our clusters. At first we wanted to use the K-Nearest Neighbors algorithm, but we quickly discovered this was a supervised learning method. This means it classifies items based on a label, which for songs could be something like genre. Since we decided we want to group songs based on similarity, we realized an unsupervised learning method would be more suitable. We therefore went with the K-means algorithm. 

Next, we had to decide what module to use to implement the machine learning algorithm. We had heard positive reviews on tensorflow, but found more information on K-means being implemented with scikit learn. We decided to install and start working with both modules to find which we found easiest. By doing this, we discovered we made bigger steps with our scikit implementation, which is why we decided to continue using it. 

#### Implementation

Regarding our code structure, we followed the [class Diagram](https://gitlab.ewi.tudelft.nl/ewi3615tu/2019-2020/data/ewi3615tu-ds10/ewi3615tu-ds10/blob/master/Documentation%20set/Design%20plan/Design%20diagrams%20and%20visualisations/Class_diagram_v8.png) from our Design Plan. During coding we sometimes discovered some extra functionalities we needed or functions that made some code redundant. For example, we added a function called 'elbow' to evaluate the optimal K value for our KMeans class using the elbow method. We also extracted some methods from functions we used often and added extra class atributes. 

We implemented the most important features we defined in our [prioritized requirement list](https://gitlab.ewi.tudelft.nl/ewi3615tu/2019-2020/data/ewi3615tu-ds10/ewi3615tu-ds10/blob/master/Documentation%20set/Development%20plan/Development%20Plan.md), but decided to let go of the 'could have's and 'won't have's. We all agreed that letting a user select two different songs to calculate their similarity would not contribute to our program's goal, which was to create lists of similar songs rather than to compare songs one to one. 
We also wanted to gather user input, such as a rating of the clustering quality, and use this information to improve the functionality of our algorithm. Unfortunately, we found out this would be too difficult to incorporate into our project. The K-Means algorithm bases its clustering on the audio features instead of previous results, which makes it impossible to easily incorporate user feedback. 
Besides, we did not include the requirement to let a user pick a song and generate a playlist based on this song, as the clusters that are given as output right now can be interpreted as playlists already. 
Finally, we decided to let a user select a country and recurrence (daily/weekly), but not the date of the chart they want to gather results for. We thought this option would not add extra value to our program. 

In visualizing the minimum spanning tree, we ran into a problem, as already stated in the *Risk factors*. Since a minimum spanning tree only contains information on the distance between connected songs, the positioning of unconnected nodes is arbitrary. Therefore, it is not possible to conclude anything about the similarity of songs that are not connected on the graph. To solve this, we tried to base the positions of the nodes on the graph containing information on the distance between all of the possible pairs of songs. Since this original graph has a very large number of edges, running a node positioning algorithm on this does not give useful results. 
Since we could not achieve the desired visualization with our minimum spanning tree alone, we started looking for another way to visualize our clusters, which is why we decided to also plot our data using Principal Component Analysis (PCA). We now reduce the dimensions of each song from 10 audio features to 3 principal components and output a 3D scatter plot in which each song is colored according to cluster. This plot gave us a way to evaluate our clusters more visually and intuitively. 

#### End product

Our final program asks for user input to determine the region and occurence (daily/weekly) of the chart, of which an example is given [here](https://gitlab.ewi.tudelft.nl/ewi3615tu/2019-2020/data/ewi3615tu-ds10/ewi3615tu-ds10/blob/master/Documentation%20set/Evaluation/Global_daily_9-1-2020_user_input.JPG).
The application then takes some time to process and outputs:

a) 10 lists of the clustered songs. ([example](https://gitlab.ewi.tudelft.nl/ewi3615tu/2019-2020/data/ewi3615tu-ds10/ewi3615tu-ds10/blob/master/Documentation%20set/Evaluation/Global_daily_9-1-2020_cluster_0.JPG))

b) Two minimum spanning trees: One simple version showing the positions and cluster colors ([example](https://gitlab.ewi.tudelft.nl/ewi3615tu/2019-2020/data/ewi3615tu-ds10/ewi3615tu-ds10/blob/master/Documentation%20set/Evaluation/MST_simple_global_daily_9-1-2020.jpg)) and one version with song numbers, which correspond to the indices in the cluster list ([example](https://gitlab.ewi.tudelft.nl/ewi3615tu/2019-2020/data/ewi3615tu-ds10/ewi3615tu-ds10/blob/master/Documentation%20set/Evaluation/MST_Global_daily_9-1-2020_pdf_version_including_numbers.pdf)).

c) A 3D scatter plot of the songs in the different clusters achieved with PCA, to show the placement of the different clusters. The plot is shown from three different angles. ([example](https://gitlab.ewi.tudelft.nl/ewi3615tu/2019-2020/data/ewi3615tu-ds10/ewi3615tu-ds10/blob/master/Documentation%20set/Evaluation/PCA_Global_daily_9-1-2020.pdf))


#### Results

To find out whether it is actually possible to accurately cluster similar songs based on Spotify's audio features, we ran our program and analyzed the results. 

To see whether the clusters are well formed, we first look at an example of our [minimum spanning tree](https://gitlab.ewi.tudelft.nl/ewi3615tu/2019-2020/data/ewi3615tu-ds10/ewi3615tu-ds10/blob/master/Documentation%20set/Evaluation/MST_simple_global_daily_9-1-2020.jpg). In the minimum spanning tree we can recognize groups of connected nodes with the same color, which means there are similar songs in the same cluster. However, as discussed above in the Implementation section, we cannot conclude anything on the position of nodes that are not connected with an edge. Therefore it was to be expected there are different groups of a certain cluster scattered in the plot. Therefore, the minimum spanning tree does not give us all of the desired information on our clusters.

In the [3D visualisation created by doing PCA](https://gitlab.ewi.tudelft.nl/ewi3615tu/2019-2020/data/ewi3615tu-ds10/ewi3615tu-ds10/blob/master/Documentation%20set/Evaluation/PCA_Global_daily_9-1-2020.pdf), we can see the different clusters much better. It is clearly visible that the songs of a certain cluster can be found together, but there is no clear distinction between the different clusters. This means that a song on the edge of a cluster can be closer to a song from another cluster than to a song of its own cluster. 
Another thing that clearly stands out is that the pink song from cluster 5 is located quite far from the other songs. When we look up the song in the cluster list ([click here to see](https://gitlab.ewi.tudelft.nl/ewi3615tu/2019-2020/data/ewi3615tu-ds10/ewi3615tu-ds10/blob/master/Documentation%20set/Evaluation/Global_daily_9-1-2020_cluster_5.JPG)), we find the song 'Everything I Wanted' by Billie Eilish. When we ran our program, this song was (almost) always in its own cluster, every now and then bundling with one other song. When you [listen to this song](https://open.spotify.com/album/4i3rAwPw7Ln2YrKDusaWyT), you find out it is a very soft and slow song, which is indeed very different from the other songs in the chart. 

The examples of the minimum spanning tree and PCA plot were created for the global daily chart of 9-1-2020 and show results that are really similar to all of the visualisations we have seen for different charts.

As can be read in our [test and validation results](https://gitlab.ewi.tudelft.nl/ewi3615tu/2019-2020/data/ewi3615tu-ds10/ewi3615tu-ds10/blob/master/Documentation%20set/Test%20and%20validation%20results/Testing%20and%20validation%20results.md), applying the elbow- and silhouette method indicated the same problem: The clusters of the songs are not distinct. 

To validate our computed clusters, we finally manually tested the results, which can also be read in [test and validation results](https://gitlab.ewi.tudelft.nl/ewi3615tu/2019-2020/data/ewi3615tu-ds10/ewi3615tu-ds10/blob/master/Documentation%20set/Test%20and%20validation%20results/Testing%20and%20validation%20results.md). 
We all listened to a saved Spotify chart to make our own clusters, after which we put the playlist through the algorithm to see if our program gave the same results. We immediately found out that it is difficult to cluster songs solely based on audio features. As we know these songs, we already had an association with them, automatically causing us to, for example, cluster Christmas songs together easily. Our own results were quite different from each other and also from the clusters formed by the algorithm. Although most of us placed the Christmas songs together in one cluster, our algorithm divided them over many different clusters. However, certain songs we all put together in a single cluster could also be found in a cluster created by K-Means. 
We also tested it the other way around, letting Spotichart make a cluster and validating whether we would have clustered those songs together as well. It turned out some of the clusters showed a clear pattern and included similar songs, whereas other clusters contained songs that were not that similar. Almost every cluster contained some outliers which were mainly rap songs that we would cluster separately. Also there were some clusters that we would have split up because it contained two main genres. 


#### Conclusion

In conclusion, our algorithm is able to cluster similar songs together to some extent. Especially if one is looking for songs with a similar tempo and energy, such as very upbeat and danceable songs as opposed to slower songs, our algorithm can make a good division. However, the clusters that are created are not distinct. This results in songs within a cluster mostly being similar to one another, but not necessarily different from songs in other clusters. 

Moreover, our algorithm is not able to capture the feeling many people get when listening to a song. To go back to the example of Christmas songs: even though Christmas songs can have a great range in tempo, danceability etc., most of us would classify them into one category, whereas our algorithm does not do this. Besides, our algorithm cannot predict whether someone who really likes a certain song will also like the other songs in the cluster. This is because we do not only base our liking of a song on the beat and energy, but also on the lyrics and the general feel of the song. This cannot be entirely covered by Spotify's audio features.
To create a similar program that would account for these kind of things, one would have to use a machine learning algorithm that uses Spotify user data to gather information on which songs are often liked by the same people. This is exactly the kind of tool Spotify applies to help people find new music. [(*source*)](https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe)

